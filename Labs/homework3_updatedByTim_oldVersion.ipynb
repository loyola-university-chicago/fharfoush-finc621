{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINC621 Winter 2018-19 Lab Worksheet 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subtitle: Variance, Covariance, Correlation & Causality (finc621-lab03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### author: \"Yu Jia\"\n",
    "\n",
    "#### date: \"11/28/2018\"\n",
    "\n",
    "#### output:\n",
    "  #### html_notebook: default\n",
    "  #### html_document: default\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "\n",
    "In this worksheet we look at different variance, covariance, volatility, and causality calculations. We finish with a short matematical proof (no R required).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Remember to always set your working directory to the source file location. Go to 'Session', scroll down to 'Set Working Directory', and click 'To Source File Location'. Read carefully the below and follow the instructions to complete the tasks and answer any questions.  Submit your work to RPubs as detailed in previous notes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "For clarity, tasks/questions to be completed/answered are highlighted in red color (color visible only in preview mode) and numbered according to their particular placement in the task section.  Type your answers outside the red color tags!\n",
    "\n",
    "\n",
    "Quite often you will need to add your own code chunk. Execute sequentially all code chunks, preview, publish, and submit link on Sakai following the naming convention. Make sure to add comments to your code where appropriate. Use own language!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Any sign of plagiarism, will result in dissmissal of work!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Variance, Covariance, and Volatility\n",
    "\n",
    "This task follows the two examples in the book `R Example 2.5/p. 58` and `R Example 2.6/p. 66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>##### 1A) Calculate the correlation and covariance matrix of the adjusted daily log returns for four different stocks of your choice. Explain your observations in terms of potential relationships.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol=['TSLA','BABA','AMZN','FB']\n",
    "df=web.DataReader(symbol,'yahoo',2015-1-1,2019-1-1)\n",
    "# tsla daily log return\n",
    "Treturn=np.log(df['Adj Close','TSLA']).diff().dropna()\n",
    "# pd.to_numeric(Treturn,downcast='float')\n",
    "# baba daily log return\n",
    "Breturn=np.log(df['Adj Close','BABA']).diff().dropna()\n",
    "# amzn daily log return\n",
    "Areturn=np.log(df['Adj Close','AMZN']).diff().dropna()\n",
    "# fb daily log return\n",
    "Freturn=np.log(df['Adj Close','FB']).diff().dropna()\n",
    "# create matrix \n",
    "M=pd.concat([Treturn,Breturn,Areturn,Freturn],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>BABA</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>FB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Adj Close</th>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BABA</th>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Adj Close                              \n",
       "                    TSLA      BABA      AMZN        FB\n",
       "Adj Close TSLA  0.000967  0.000148  0.000173  0.000191\n",
       "          BABA  0.000148  0.000426  0.000134  0.000110\n",
       "          AMZN  0.000173  0.000134  0.000373  0.000176\n",
       "          FB    0.000191  0.000110  0.000176  0.000458"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance of matrix\n",
    "M.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>BABA</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>FB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Adj Close</th>\n",
       "      <th>TSLA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.288648</td>\n",
       "      <td>0.288014</td>\n",
       "      <td>0.286310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BABA</th>\n",
       "      <td>0.288648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.331706</td>\n",
       "      <td>0.313776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.288014</td>\n",
       "      <td>0.331706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>0.286310</td>\n",
       "      <td>0.313776</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Adj Close                              \n",
       "                    TSLA      BABA      AMZN        FB\n",
       "Adj Close TSLA  1.000000  0.288648  0.288014  0.286310\n",
       "          BABA  0.288648  1.000000  0.331706  0.313776\n",
       "          AMZN  0.288014  0.331706  1.000000  0.425165\n",
       "          FB    0.286310  0.313776  0.425165  1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation of matrix\n",
    "M.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>##### 1B) Calculate the three types of volatility for a particular stock of your choice. Consider a time window extending one year back from most recent obtainable closing day price. Order the three estimates from low to high volatility and explain how the ordering makes sense.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain TSLA adjusted Close price data from 2017-9 to 2018-10\n",
    "# tsla=df.loc[['2017-9','2018-10'],['Adj Close','TSLA']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_parkinson(item):\n",
    "    \"\"\" \n",
    "    Calculates the Parkinson volatility of a MultiIndexed Pandas DataFrame \n",
    "  \n",
    "    Parameters: \n",
    "    item (DataFrame)\n",
    "  \n",
    "    Returns: \n",
    "    float: The calculated volatility\n",
    "    \"\"\"\n",
    "    \n",
    "    # First we need to know how many items are in the data set\n",
    "    m = int(item['High'].count())\n",
    "    \n",
    "    # We set the sum to zero and then iterate through the data\n",
    "    sum = 0.0\n",
    "    for index, row in item.iterrows():\n",
    "        high = float(row['High'])\n",
    "        low = float(row['Low'])\n",
    "        \n",
    "        if math.isnan(low): # Check to see if there is null data in the denominator\n",
    "            m = m - 1 # If so, decrease the number of items in the data set, and move to the next iteration\n",
    "            continue\n",
    "            \n",
    "        sum += (math.log(high / low)) ** 2\n",
    "    \n",
    "    # We perform the rest of the calcuation and then send result value back\n",
    "    return(math.sqrt((1 / (4 * math.log(2))) * (1 / m) * sum))\n",
    "   \n",
    "def calculate_garman_klass(item):\n",
    "    \"\"\" \n",
    "    Calculates the Garman Klass volatility of a MultiIndexed Pandas DataFrame \n",
    "  \n",
    "    Parameters: \n",
    "    item (DataFrame)\n",
    "  \n",
    "    Returns: \n",
    "    float: The calculated volatility\n",
    "    \"\"\"\n",
    "    \n",
    "    # First we need to know how many items are in the data set\n",
    "    m = int(item['High'].count())\n",
    "    \n",
    "    # We set the sum to zero and then iterate through the data\n",
    "    sum = 0.0\n",
    "    for index, row in item.iterrows():\n",
    "        high = float(row['High'])\n",
    "        low = float(row['Low'])\n",
    "        closing = float(row['Close'])\n",
    "        opening = float(row['Open'])\n",
    "\n",
    "        if math.isnan(low) or math.isnan(opening): # Check to see if there is null data in the denominator\n",
    "            m = m - 1 # If so, decrease the number of items in the data set, and move to the next iteration\n",
    "            continue\n",
    "            \n",
    "        sum += (0.5 * (math.log(high / low)) ** 2 - (2 * math.log(2) - 1) * (math.log(closing / opening) ** 2))\n",
    "    \n",
    "    # We perform the rest of the calcuation and then send result value back\n",
    "    return(math.sqrt(1 / m * sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkinson volatility for  Tesla is:  0.026187376988483845\n",
      "Parkinson volatility for  Alibaba is:  0.035604425898633905\n",
      "Parkinson volatility for  Amazon is:  0.014364686178111132\n",
      "Parkinson volatility for  Facebook is:  0.016842010608405292\n",
      "Garman and Klass volatility for  Tesla is:  0.026340640417009974\n",
      "Garman and Klass volatility for  Alibaba is:  0.035529724976171795\n",
      "Garman and Klass volatility for  Amazon is:  0.014384841148138651\n",
      "Garman and Klass volatility for  Facebook is:  0.01683996237813042\n"
     ]
    }
   ],
   "source": [
    "# Isolate the data from the data frame\n",
    "tesla = df.loc[:,(df.columns.get_level_values(1) == 'TSLA')]\n",
    "alibaba = df.loc[:,(df.columns.get_level_values(1) == 'BABA')]\n",
    "amazon = df.loc[:,(df.columns.get_level_values(1) == 'AMZN')]\n",
    "facebook = df.loc[:,(df.columns.get_level_values(1) == 'FB')]\n",
    "\n",
    "# Set up a dictionary to hold the values\n",
    "p_volatility = {}\n",
    "p_volatility[\"Tesla\"] = calculate_parkinson(tesla)\n",
    "p_volatility[\"Alibaba\"] = calculate_parkinson(alibaba)\n",
    "p_volatility[\"Amazon\"] = calculate_parkinson(amazon)\n",
    "p_volatility[\"Facebook\"] = calculate_parkinson(facebook)\n",
    "\n",
    "# Set up a dictionary to hold the values\n",
    "gk_volatility = {}\n",
    "gk_volatility[\"Tesla\"] = calculate_garman_klass(tesla)\n",
    "gk_volatility[\"Alibaba\"] = calculate_garman_klass(alibaba)\n",
    "gk_volatility[\"Amazon\"] = calculate_garman_klass(amazon)\n",
    "gk_volatility[\"Facebook\"] = calculate_garman_klass(facebook)\n",
    "\n",
    "# You can print all the values like this:\n",
    "for item in p_volatility:\n",
    "    print(\"Parkinson volatility for \", item, \"is: \", p_volatility[item])\n",
    "    \n",
    "for item in gk_volatility:\n",
    "    print(\"Garman and Klass volatility for \", item, \"is: \", gk_volatility[item])\n",
    "\n",
    "# You can also print the values 1 at a time like this:\n",
    "# print(p_volatility[\"Tesla\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ git clonen http://github.com/volatilityfoundation/volatility.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a volatility folder that contains the source code and you can run volatility derectory from there.\n",
    "import sys\n",
    "! git clone http://github.com/volatilityfoundation/volatility.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Auto-Correlation and Auto-Regression\n",
    "\n",
    "Follow the example in the book  `R Example 3.2/p. 74` and `R Example 4.1/p. 115`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>##### 2A) Calculate the ACF for a stock of your choice. Consider both the log return and squared log return. Interpret your results in terms of possible existence of autocorrelation.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m conda install statsmodels.graphics.tsaplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate daily log return of TSLA and squared log return of TSLA\n",
    "TSLA_logreturn=np.log(df['Adj Close','TSLA']).diff().dropna()*100\n",
    "TSLA_Slogreturn=np.log(df['Adj Close','TSLA']).diff().dropna()**2*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot autocorrelation of daily log return of TSLA\n",
    "fig=plot_acf(TSLA_logreturn,lags=30)\n",
    "fig.set_size_inches(15.5,10.5,forward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation of square daily log return of TSLA\n",
    "figs=plot_acf(TSLA_Slogreturn,lags=30)\n",
    "figs.set_size_inches(15.5,10.5,forward=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>##### 2B) Plot the exchange rate for USD versus another currency of your choice. Interpret your results in terms of behavior.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain U.S/Euro data from FRED\n",
    "euro=web.DataReader('DEXUSEU','fred')\n",
    "euro.plot(figsize=(12,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>##### 2C) Test for the possible existence of an underlying AR(1) â€“ Markov process in your exchange rate currency pair. To this end, plot the ACF and the partial ACF (PACF). Interpret your results.  Clearly refer to the lags, and their impacts in determining the order.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot partial autocorrelation of exchange rate of currency\n",
    "fig_3=plot_pacf(euro, lags=15)\n",
    "fig_3.set_size_inches(15.5,10.5,forward=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Granger Causality Test\n",
    "\n",
    "To conduct this test the package `lmtest` will be required, as already done in the code chunk below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>##### 3A) Include below the code chunk to solve for 3.5.7 R Lab/p. 106.  Write your conclusions.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_contents('statsmodels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USMoney=pd.read_excel(\"/Users/hangxigudeaoqi/Desktop/USMoney.xlsx\")\n",
    "USMoney.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=USMoney['gnp']\n",
    "b=USMoney['m1']\n",
    "x=np.column_stack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grangercausalitytests(x,maxlag=15,addconst=True,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b is m1, a is gnp\n",
    "y=np.column_stack((b,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grangercausalitytests(y,maxlag=15,addconst=True,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>The Null hypothesis for grangercausality is that time series in the second column doesn't granger cause the time series in the first column. Granger causality means that past values of the second column have a statistically significant effect on the current value of the first column, taking past values of the first column into account as regressors. We reject the null hypothesis that the second column doesn't granger cause the first column if the p-value are below a desiredd size of the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>##### 3B) Briefly describe the data in terms of time range and variables. Similar to the linear autoregressive model described in class, write the mathematical regression model solved in each Granger test, including the proper order. Use naming conventions, and notations more reflective of the data set considered for  `USMoney`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Y_t=a_0+a_1Y_1+a_2Y_2+a_3Y_3+b_1 X_1+b_2X_2+b_3X_3$\n",
    "In the first Granger causality test, x is the M1 and y is the GNP. \n",
    "When p-value is below 0.5, one rejects null hypothesis that M1 doesn't cause the GNP. In other words, the M1 causes the GNP.\n",
    "In the second Granger causality test, x is the GNP and y is the M1.\n",
    "When p-value is abover 0.5, one accpect null hypothesis. It means that the GNP doesn't causes the M1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Mathematical Proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>##### 4A) Prove the two results in Eq (2.32)/p. 53.  No R-coding is needed here.  Clearly show your steps. Hint: Use the definition of $E(X^n)$ for X-log normally distributed.   Observe also that $Var(X) = E(X^2)-E^2(X)$ for any random variable X.<font/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The moments of the variable X are\n",
    "$E(X^n)=e^{nu+1/2n^2\\sigma^2}$,n>0\n",
    "assuming ${R_{t}}$ is log-normally distributed, since $r_{t}=ln(R_{t}+1)$\n",
    "$e^{r}=R+1$, then $R=e^{r}-1$,in $E(X^n)=e^{nu+1/2n^2\\sigma^2}$\n",
    "\n",
    "when n=1: $E(R)=u_R=e^{u_r+\\sigma^2_r/2}-1$\n",
    "\n",
    "when n=2,input in formula , the result $E(x^2)=E(R^2)-E^2(R)=e^{2u_r+2\\sigma^2_r}-(e^{u_r+\\sigma^2_r/2})^2=e^{2u_r+\\sigma^2_r}(e^{\\sigma^2_r}-1)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1311px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
